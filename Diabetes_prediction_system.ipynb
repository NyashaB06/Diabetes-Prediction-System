{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF31b4cgcDdq"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# üîπ CGM-Only LSTM & GRU (without extra food related data)\n",
        "# ==============================\n",
        "\n",
        "!pip install tensorflow scikit-learn matplotlib pandas --quiet\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ==============================\n",
        "# 1Ô∏è‚É£ Load and Prepare Data\n",
        "# ==============================\n",
        "file_path = \"/content/drive/MyDrive/diabetes/Subject 1_3hr.csv\"  # ‚úÖ Update if needed\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "if 'CGM' not in data.columns:\n",
        "    raise ValueError(\"‚ùå 'CGM' column not found in dataset!\")\n",
        "\n",
        "# Smooth the CGM signal (rolling mean)\n",
        "data['CGM_smooth'] = data['CGM'].rolling(window=3, center=True).mean()\n",
        "data = data.dropna(subset=['CGM_smooth']).reset_index(drop=True)\n",
        "\n",
        "# Normalize\n",
        "scaler = MinMaxScaler()\n",
        "scaled_cgm = scaler.fit_transform(data[['CGM_smooth']])\n",
        "\n",
        "# ==============================\n",
        "# 2Ô∏è‚É£ Create Sequence Data\n",
        "# ==============================\n",
        "def create_sequences(dataset, window=20):\n",
        "    X, y = [], []\n",
        "    for i in range(len(dataset) - window):\n",
        "        X.append(dataset[i:i + window])\n",
        "        y.append(dataset[i + window])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "window_size = 20\n",
        "X, y = create_sequences(scaled_cgm, window_size)\n",
        "\n",
        "# Split data sequentially (no shuffle)\n",
        "split = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "print(f\"‚úÖ Data prepared: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
        "\n",
        "# ==============================\n",
        "# 3Ô∏è‚É£ Define Models\n",
        "# ==============================\n",
        "\n",
        "# LSTM\n",
        "lstm_model = Sequential([\n",
        "    LSTM(128, activation='tanh', return_sequences=True, input_shape=(window_size, 1)),\n",
        "    Dropout(0.2),\n",
        "    LSTM(64, activation='tanh', return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm_model.compile(optimizer=Adam(0.001), loss='mse')\n",
        "\n",
        "# GRU\n",
        "gru_model = Sequential([\n",
        "    GRU(128, activation='tanh', return_sequences=True, input_shape=(window_size, 1)),\n",
        "    Dropout(0.2),\n",
        "    GRU(64, activation='tanh', return_sequences=False),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "gru_model.compile(optimizer=Adam(0.001), loss='mse')\n",
        "\n",
        "# ==============================\n",
        "# 4Ô∏è‚É£ Train (100 Epochs)\n",
        "# ==============================\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"\\nüöÄ Training LSTM...\")\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100, batch_size=8, validation_split=0.2,\n",
        "    verbose=1, callbacks=[es]\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Training GRU...\")\n",
        "history_gru = gru_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100, batch_size=8, validation_split=0.2,\n",
        "    verbose=1, callbacks=[es]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5Ô∏è‚É£ Evaluate Models\n",
        "# ==============================\n",
        "def evaluate_model(model, X_test, y_test, name):\n",
        "    preds = model.predict(X_test).flatten()\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    print(f\"\\nüìä {name} Results:\")\n",
        "    print(f\"R¬≤   = {r2:.4f}\")\n",
        "    print(f\"RMSE = {rmse:.6f}\")\n",
        "    print(f\"MAE  = {mae:.6f}\")\n",
        "    return {\"Model\": name, \"R2\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
        "\n",
        "lstm_results = evaluate_model(lstm_model, X_test, y_test, \"LSTM\")\n",
        "gru_results = evaluate_model(gru_model, X_test, y_test, \"GRU\")\n",
        "\n",
        "# ==============================\n",
        "# 6Ô∏è‚É£ Plot Predictions\n",
        "# ==============================\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_test, label=\"True CGM\", linewidth=2)\n",
        "plt.plot(lstm_model.predict(X_test), label=f\"LSTM (R¬≤={lstm_results['R2']:.2f})\", alpha=0.8)\n",
        "plt.plot(gru_model.predict(X_test), label=f\"GRU (R¬≤={gru_results['R2']:.2f})\", alpha=0.8)\n",
        "plt.title(\"üìà CGM Prediction (True vs Predicted)\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Scaled CGM\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 7Ô∏è‚É£ Save Results Only\n",
        "# ==============================\n",
        "save_dir = \"/content/drive/MyDrive/diabetes/results/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "results_df = pd.DataFrame([lstm_results, gru_results])\n",
        "results_path = os.path.join(save_dir, \"CGM_LSTM_GRU_results.csv\")\n",
        "results_df.to_csv(results_path, index=False)\n",
        "\n",
        "print(\"\\n‚úÖ Results saved successfully at:\", results_path)\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2m-AKYucsRc"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# üîπ Traditional ML Models for CGM-Only Data(without extra food related data)\n",
        "# ==============================\n",
        "\n",
        "!pip install lightgbm scikit-learn pandas --quiet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "# ==============================\n",
        "# 1Ô∏è‚É£ Reuse Preprocessed Data\n",
        "# ==============================\n",
        "# Make sure you‚Äôve run the previous LSTM-GRU section first.\n",
        "# It already defines: X_train, X_test, y_train, y_test\n",
        "\n",
        "print(f\"‚úÖ Using existing data shapes: X_train={X_train.shape}, X_test={X_test.shape}\")\n",
        "\n",
        "# Flatten sequence data for traditional models\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# ==============================\n",
        "# 2Ô∏è‚É£ Define Traditional Models\n",
        "# ==============================\n",
        "models = {\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
        "    \"ExtraTrees\": ExtraTreesRegressor(n_estimators=200, random_state=42),\n",
        "    \"HistGB\": HistGradientBoostingRegressor(random_state=42),\n",
        "    \"LightGBM\": lgb.LGBMRegressor(n_estimators=200, random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "# ==============================\n",
        "# 3Ô∏è‚É£ Train and Evaluate\n",
        "# ==============================\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nüöÄ Training {name}...\")\n",
        "    model.fit(X_train_flat, y_train)\n",
        "    preds = model.predict(X_test_flat)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    results.append({\"Model\": name, \"R2\": r2, \"RMSE\": rmse, \"MAE\": mae})\n",
        "    print(f\"{name}: R2={r2:.3f}, RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 4Ô∏è‚É£ Save Results to Same File\n",
        "# ==============================\n",
        "save_dir = \"/content/drive/MyDrive/diabetes/results/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "results_path = os.path.join(save_dir, \"CGM_LSTM_GRU_results.csv\")\n",
        "\n",
        "# Append new results to the file created by the LSTM/GRU section\n",
        "if os.path.exists(results_path):\n",
        "    existing_results = pd.read_csv(results_path)\n",
        "    final_results = pd.concat([existing_results, pd.DataFrame(results)], ignore_index=True)\n",
        "else:\n",
        "    final_results = pd.DataFrame(results)\n",
        "\n",
        "final_results.to_csv(results_path, index=False)\n",
        "\n",
        "print(\"\\n‚úÖ All Results Saved at:\", results_path)\n",
        "print(final_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erVNpAReqcrd"
      },
      "outputs": [],
      "source": [
        "import numpy as np, tensorflow as tf\n",
        "print(\"‚úÖ NumPy:\", np.__version__)\n",
        "print(\"‚úÖ TensorFlow:\", tf.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrIqwIsO--PA"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 1_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcDmWVe_XV_V"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "# ================================\n",
        "# üíæ Mount Drive\n",
        "# ================================\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 2_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPelX8WSCCE3"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 3_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yFRgORhXZjb"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 4_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rlsdNmqXbxX"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 5_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s718QiKPXeA5"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 6_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnU4vTzKXgAf"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 7_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfOEny8sXhpb"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 8_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF701f8CXjWS"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 9_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgl2S4WQXlO2"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 10_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DartWhrMXm_5"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 11_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CxJwYP4YevM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jL7IC3xYfFw"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 12_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gRCCuhCYrMX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XJ7xDn9Yrac"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 13_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWuM76niYsoi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM4UHILIYs24"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 14_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRY5iIVwYuAV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUtxC3wMYuSO"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 15_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4uEdOCPYvcR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPjJSXC-Yvpp"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 16_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww3FQcKeYzUs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ij42prYYzmU"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 17_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLon5XUVY02l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuDIVVJTY1BV"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 18_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VB5m--3Y2ki"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKV4ngDlY2x5"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 19_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWSHnb0nY4G-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHWTe8irY4Wq"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 20_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pLEzExtY7vg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rToB5zKbY8AX"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 21_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8JTCSIAY9D5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPL6sB-1Y9RD"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 22_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egbNsNfKY-64"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk0Fhyq2Y_GS"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 23_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvtnq1IKZAiS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU2F226sZBDR"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 24_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gee5X3msZC3x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H17fTcUZDD1"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ======================================\n",
        "# Load & Prepare Data\n",
        "# ======================================\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/diabetes/Subject 25_3hr.csv\")\n",
        "cgm_col = [c for c in df.columns if 'cgm' in c.lower()][0]\n",
        "\n",
        "# If time column exists\n",
        "if 'EventDateTime' in df.columns:\n",
        "    df['EventDateTime'] = pd.to_datetime(df['EventDateTime'])\n",
        "    df = df.set_index('EventDateTime').sort_index()\n",
        "    df = df.resample('15min').interpolate()\n",
        "\n",
        "cgm = df[cgm_col].dropna().values.reshape(-1, 1)\n",
        "\n",
        "print(\"\\n‚úÖ CGM Summary:\")\n",
        "print(df[cgm_col].describe())\n",
        "\n",
        "# ======================================\n",
        "# Split + Scale\n",
        "# ======================================\n",
        "train_size = int(len(cgm) * 0.8)\n",
        "train, test = cgm[:train_size], cgm[train_size:]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "train_scaled = scaler.fit_transform(train)\n",
        "test_scaled = scaler.transform(test)\n",
        "\n",
        "# ======================================\n",
        "# Create Sequences\n",
        "# ======================================\n",
        "def create_sequences(data, lookback=60):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - lookback):\n",
        "        X.append(data[i:i + lookback])\n",
        "        y.append(data[i + lookback])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "lookback = 60\n",
        "X_train, y_train = create_sequences(train_scaled, lookback)\n",
        "X_test, y_test = create_sequences(test_scaled, lookback)\n",
        "\n",
        "# ======================================\n",
        "# LSTM Model\n",
        "# ======================================\n",
        "lstm = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dense(1)\n",
        "])\n",
        "lstm.compile(optimizer='adam', loss='mse')\n",
        "lstm.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "          validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "lstm_train = lstm.predict(X_train)\n",
        "lstm_test = lstm.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# GRU Model\n",
        "# ======================================\n",
        "gru = Sequential([\n",
        "    GRU(128, return_sequences=True, input_shape=(lookback, 1)),\n",
        "    Dropout(0.3),\n",
        "    GRU(64),\n",
        "    Dense(1)\n",
        "])\n",
        "gru.compile(optimizer='adam', loss='mse')\n",
        "gru.fit(X_train, y_train, epochs=40, batch_size=16, verbose=0,\n",
        "         validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
        "\n",
        "gru_train = gru.predict(X_train)\n",
        "gru_test = gru.predict(X_test)\n",
        "\n",
        "# ======================================\n",
        "# Meta Learners\n",
        "# ======================================\n",
        "X_train_meta = np.hstack([lstm_train, gru_train])\n",
        "X_test_meta = np.hstack([lstm_test, gru_test])\n",
        "\n",
        "meta_lr = LinearRegression().fit(X_train_meta, y_train)\n",
        "meta_rf = RandomForestRegressor(n_estimators=200, random_state=42).fit(X_train_meta, y_train.ravel())\n",
        "\n",
        "pred_lr = scaler.inverse_transform(meta_lr.predict(X_test_meta).reshape(-1,1))\n",
        "pred_rf = scaler.inverse_transform(meta_rf.predict(X_test_meta).reshape(-1,1))\n",
        "y_true = scaler.inverse_transform(y_test.reshape(-1,1))\n",
        "\n",
        "# ======================================\n",
        "# Evaluate\n",
        "# ======================================\n",
        "for name, pred in zip([\"Linear Regression\", \"Random Forest\"], [pred_lr, pred_rf]):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
        "    r2 = r2_score(y_true, pred)\n",
        "    print(f\"\\nüìä {name} Meta Results: RMSE={rmse:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(y_true, label=\"Actual\", color='blue')\n",
        "plt.plot(pred_rf, label=\"Predicted (RF)\", color='red')\n",
        "plt.title(\"CGM Prediction - LSTM+GRU+RF Hybrid\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}